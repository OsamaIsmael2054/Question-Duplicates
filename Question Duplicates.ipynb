{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dc4e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import layers\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "import random as rnd\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2932b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./questions.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89723e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5eb18a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 300000 Test set: 10240\n"
     ]
    }
   ],
   "source": [
    "N_train = 300000\n",
    "N_test  = 10*1024\n",
    "df_train = df[:N_train]\n",
    "df_test  = df[N_train:N_train+N_test]\n",
    "print(\"Train set:\", len(df_train), \"Test set:\", len(df_test))\n",
    "del(df) # remove to free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ff60ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = df_train[df_train['is_duplicate'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f9e1c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenzer = Tokenizer(oov_token=\"oov\")\n",
    "tokenzer.fit_on_texts(data_train[\"question1\"])\n",
    "tokenzer.fit_on_texts(data_train[\"question2\"])\n",
    "Q1_tokened = tokenzer.texts_to_sequences(data_train[\"question1\"])\n",
    "Q2_tokened = tokenzer.texts_to_sequences(data_train[\"question2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9232583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28139"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenzer.word_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01eab25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_train = pad_sequences(Q1_tokened, maxlen=100, padding='post', truncating='post')\n",
    "Q2_train = pad_sequences(Q2_tokened, maxlen=100, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d0ecc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = tf.data.Dataset.from_tensor_slices((Q1_train,Q2_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9929a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_size = int(0.2*len(Data))\n",
    "valid = Data.take(valid_size).batch(128,drop_remainder=True)\n",
    "train = Data.skip(valid_size).shuffle(1000).batch(128,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e6029b",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7688f149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_base_network(vocab_size = 41699,d_model = 128):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Embedding(vocab_size, 128))\n",
    "    model.add(layers.LSTM(128,activation='relu'))\n",
    "    model.add(layers.Dense(128))\n",
    "    model.add(layers.Lambda(lambda x: K.l2_normalize(x,axis=1)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e70b2c8",
   "metadata": {},
   "source": [
    "# Define Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e44b997",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss Function\n",
    "from tensorflow.keras.losses import Loss\n",
    "class TripletLoss(Loss):\n",
    "    def __init__(self,margin):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.margin = margin\n",
    "        \n",
    "    def call(self,v1,v2):\n",
    "        scores = tf.matmul(v1, tf.transpose(v2))  \n",
    "\n",
    "        batch_size = len(scores)\n",
    "\n",
    "        positive = tf.linalg.diag_part(scores)  \n",
    "\n",
    "        #closest negative\n",
    "        negative_without_positive = scores - 2.0 * tf.eye(batch_size)\n",
    "\n",
    "        closest_negative = tf.math.reduce_max(negative_without_positive,axis=1)\n",
    "\n",
    "        #mean negative\n",
    "        negative_zero_on_duplicate = scores * (1.0 - tf.eye(batch_size))\n",
    "\n",
    "        mean_negative = tf.math.reduce_sum(negative_zero_on_duplicate, axis=1) / (batch_size-1)\n",
    "\n",
    "        #calculate total loss\n",
    "        triplet_loss1 = tf.math.maximum(closest_negative - positive + 0.25 ,0)\n",
    "\n",
    "        triplet_loss2 = tf.math.maximum(mean_negative - positive + 0.25 ,0)\n",
    "\n",
    "        triplet_loss = tf.math.reduce_mean(triplet_loss1 + triplet_loss2)\n",
    "\n",
    "        return triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "41fabc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "model = initialize_base_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a334f273",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f94fc127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function(model,data_train,data_valid,epochs=3):\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    loss_object = TripletLoss(0.25)\n",
    "    epochs_train_losses = []\n",
    "    epochs_val_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        #training\n",
    "        for step,(q1,q2) in enumerate(data_train):\n",
    "            with tf.GradientTape() as tape:\n",
    "                v1 = model(q1)\n",
    "                v2 = model(q2)\n",
    "                loss_value = loss_object(v1, v2)\n",
    "                \n",
    "            train_losses.append(loss_value)\n",
    "            gradients = tape.gradient(loss_value, model.trainable_weights)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "            if step % 100 == 0:\n",
    "                print(f\"Step = {step} , Train loss = {np.mean(train_losses)}\")\n",
    "            \n",
    "        #Validation\n",
    "        for q1, q2 in data_valid:\n",
    "            v1 = model(q1)\n",
    "            v2 = model(q2)\n",
    "            loss_value = loss_object(v1, v2)\n",
    "            valid_losses.append(loss_value)\n",
    "        \n",
    "        losses_train_mean = np.mean(train_losses)\n",
    "        losses_val_mean = np.mean(valid_losses)\n",
    "        epochs_val_losses.append(losses_val_mean)\n",
    "        epochs_train_losses.append(losses_train_mean)\n",
    "        \n",
    "        print('\\n Epoch %s: Train loss: %.4f  Validation Loss: %.4f' % (epoch, float(losses_train_mean), float(losses_val_mean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7d3acc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step = 0 , Train loss = 0.5000073909759521\n",
      "Step = 100 , Train loss = 0.5000094771385193\n",
      "Step = 200 , Train loss = 0.500007152557373\n",
      "Step = 300 , Train loss = 0.5000061392784119\n",
      "Step = 400 , Train loss = 0.5000055432319641\n",
      "Step = 500 , Train loss = 0.5000051856040955\n",
      "Step = 600 , Train loss = 0.5000049471855164\n",
      "\n",
      " Epoch 0: Train loss: 0.5000  Validation Loss: 0.5000\n",
      "Step = 0 , Train loss = 0.5000374913215637\n",
      "Step = 100 , Train loss = 0.5007869005203247\n",
      "Step = 200 , Train loss = 0.5004115104675293\n",
      "Step = 300 , Train loss = nan\n",
      "Step = 400 , Train loss = nan\n",
      "Step = 500 , Train loss = nan\n",
      "Step = 600 , Train loss = nan\n",
      "\n",
      " Epoch 1: Train loss: nan  Validation Loss: nan\n",
      "Step = 0 , Train loss = nan\n",
      "Step = 100 , Train loss = nan\n",
      "Step = 200 , Train loss = nan\n",
      "Step = 300 , Train loss = nan\n",
      "Step = 400 , Train loss = nan\n",
      "Step = 500 , Train loss = nan\n",
      "Step = 600 , Train loss = nan\n",
      "\n",
      " Epoch 2: Train loss: nan  Validation Loss: nan\n"
     ]
    }
   ],
   "source": [
    "training_function(model,train,valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a0cba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
